{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.060461Z",
     "iopub.status.busy": "2024-09-27T09:37:46.060229Z",
     "iopub.status.idle": "2024-09-27T09:37:46.949871Z",
     "shell.execute_reply": "2024-09-27T09:37:46.949252Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.060431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "import hashlib\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.951757Z",
     "iopub.status.busy": "2024-09-27T09:37:46.951361Z",
     "iopub.status.idle": "2024-09-27T09:37:46.960835Z",
     "shell.execute_reply": "2024-09-27T09:37:46.960056Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.951733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading raw file\n",
    "with open('documents.json', 'rb') as file:\n",
    "    docs_raw = json.load(file)\n",
    "\n",
    "# flattening raw file into list of dictionaries\n",
    "documents = [{'course': course_dict['course'], 'section': docs['section'], 'question': docs['question'], 'text': docs['text']} \\\n",
    "            for course_dict in docs_raw \\\n",
    "            for docs in course_dict['documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.962596Z",
     "iopub.status.busy": "2024-09-27T09:37:46.961957Z",
     "iopub.status.idle": "2024-09-27T09:37:46.970684Z",
     "shell.execute_reply": "2024-09-27T09:37:46.969995Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.962560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'course': 'data-engineering-zoomcamp',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Stable IDs for documents\n",
    "\n",
    "This ID will be used to reference the document in the evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.971783Z",
     "iopub.status.busy": "2024-09-27T09:37:46.971520Z",
     "iopub.status.idle": "2024-09-27T09:37:46.976095Z",
     "shell.execute_reply": "2024-09-27T09:37:46.975418Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.971762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a simple function to generate hash ids based on the concatenation of all our dictionary values\n",
    "def generate_doc_id(doc:dict) -> dict:\n",
    "\n",
    "    # first let's Concatenate the different fields together\n",
    "    combined = \"-\".join(doc.values())\n",
    "\n",
    "    # now to hash our combined unique id\n",
    "    hash_object = hashlib.md5(combined.encode()) # converts string to bytes\n",
    "\n",
    "    # generates the MD5 hash of the encoded string and converts it to a hexidecimal string\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "\n",
    "    return hash_hex[:8]  # only returning the first 8 characters of the hexidecimal string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.977759Z",
     "iopub.status.busy": "2024-09-27T09:37:46.977117Z",
     "iopub.status.idle": "2024-09-27T09:37:46.987830Z",
     "shell.execute_reply": "2024-09-27T09:37:46.987118Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.977724Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'course': 'data-engineering-zoomcamp',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'id': '7000acaa'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using our function to generate the IDs key-value pairs\n",
    "documents_updated = [doc.update({'id': generate_doc_id(doc)}) or doc for doc in documents]\n",
    "\n",
    "documents_updated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.989153Z",
     "iopub.status.busy": "2024-09-27T09:37:46.988766Z",
     "iopub.status.idle": "2024-09-27T09:37:46.995545Z",
     "shell.execute_reply": "2024-09-27T09:37:46.994875Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.989119Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's quickly check if the ids we generated are unique\n",
    "hashes = [doc['id'] for doc in documents_updated]\n",
    "\n",
    "len(documents_updated) == len(set(hashes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents_with_ids.json', 'w') as json_file:\n",
    "    json.dump(documents_updated, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an LLM model to generate questions for each record ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:46.998160Z",
     "iopub.status.busy": "2024-09-27T09:37:46.997869Z",
     "iopub.status.idle": "2024-09-27T09:37:47.012293Z",
     "shell.execute_reply": "2024-09-27T09:37:47.011762Z",
     "shell.execute_reply.started": "2024-09-27T09:37:46.998139Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# intialising the openai client so that we can use the chatgpt-4o model to generate our questions for each record ID\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m openai_client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# intialising the openai client so that we can use the chatgpt-4o model to generate our questions for each record ID\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:47.013372Z",
     "iopub.status.busy": "2024-09-27T09:37:47.013091Z",
     "iopub.status.idle": "2024-09-27T09:37:47.018349Z",
     "shell.execute_reply": "2024-09-27T09:37:47.017589Z",
     "shell.execute_reply.started": "2024-09-27T09:37:47.013352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now to create out prompt template - we will use the template provided in the course\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You emulate a student who's taking our course.\n",
    "Formulate 5 questions this student might ask based on a FAQ record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:47.019925Z",
     "iopub.status.busy": "2024-09-27T09:37:47.019462Z",
     "iopub.status.idle": "2024-09-27T09:37:47.024506Z",
     "shell.execute_reply": "2024-09-27T09:37:47.023878Z",
     "shell.execute_reply.started": "2024-09-27T09:37:47.019890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next we want to write a simple function that generates the question for each record:\n",
    "def generate_questions(doc_dict):\n",
    "    # each key in doc_dict corresponds to a placeholder in prompt_template, and the associated value will be inserted into the template\n",
    "    prompt = prompt_template.format(**doc_dict)\n",
    "    \n",
    "    responses = openai_client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role':'user', 'content': prompt}]\n",
    "    )\n",
    "    \n",
    "    return responses.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:47.025598Z",
     "iopub.status.busy": "2024-09-27T09:37:47.025305Z",
     "iopub.status.idle": "2024-09-27T09:37:47.941457Z",
     "shell.execute_reply": "2024-09-27T09:37:47.940782Z",
     "shell.execute_reply.started": "2024-09-27T09:37:47.025576Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(generate_questions(documents_updated[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:37:47.942832Z",
     "iopub.status.busy": "2024-09-27T09:37:47.942438Z",
     "iopub.status.idle": "2024-09-27T09:58:23.345714Z",
     "shell.execute_reply": "2024-09-27T09:58:23.344848Z",
     "shell.execute_reply.started": "2024-09-27T09:37:47.942805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now to generate the questions for each record id\n",
    "results = [{'Course': doc['course'], 'document_ID': doc['id'], 'Questions': generate_questions(doc)} for doc in tqdm(documents_updated)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.347145Z",
     "iopub.status.busy": "2024-09-27T09:58:23.346733Z",
     "iopub.status.idle": "2024-09-27T09:58:23.351947Z",
     "shell.execute_reply": "2024-09-27T09:58:23.351205Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.347118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's have a quick look at the results\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.353475Z",
     "iopub.status.busy": "2024-09-27T09:58:23.353048Z",
     "iopub.status.idle": "2024-09-27T09:58:23.360203Z",
     "shell.execute_reply": "2024-09-27T09:58:23.359583Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.353441Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets write a function that is able to parse our questions in results from a JSON object into a python object\n",
    "\n",
    "def parse_results(res_dict: dict) -> dict:\n",
    "    clean_dict = {}\n",
    "    \n",
    "    clean_dict['Course'] = res_dict['Course']\n",
    "    clean_dict['document_ID'] = res_dict['document_ID']\n",
    "    \n",
    "    try:\n",
    "        tmp_ques = json.loads(res_dict['Questions'])\n",
    "        if type(tmp_ques) == list:\n",
    "            clean_dict['Question'] = tmp_ques\n",
    "        else:\n",
    "            clean_dict['Question'] = list(tmp_ques.values())\n",
    "    except:\n",
    "        # the error is specific - so a hot fix for this item\n",
    "        clean_dict['Question'] = [\n",
    "            \"Why am I getting the error column c.relhasoids does not exist when using the command \\\\d <database name>?\",\n",
    "            \"What should I do to resolve the error with pgcli?\",\n",
    "            \"Should I uninstall pgcli to fix the issue?\",\n",
    "            \"What steps should I take after reinstalling pgcli?\",\n",
    "            \"Is restarting the PC necessary to resolve the error?\"\n",
    "        ]\n",
    "    \n",
    "    return clean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.361260Z",
     "iopub.status.busy": "2024-09-27T09:58:23.360990Z",
     "iopub.status.idle": "2024-09-27T09:58:23.370749Z",
     "shell.execute_reply": "2024-09-27T09:58:23.370008Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.361241Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parsed_results = [parse_results(res) for res in results]\n",
    "\n",
    "parsed_results[108]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Step - move parsed results dictionary into a dataframe and throw .csv output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.371779Z",
     "iopub.status.busy": "2024-09-27T09:58:23.371525Z",
     "iopub.status.idle": "2024-09-27T09:58:23.382784Z",
     "shell.execute_reply": "2024-09-27T09:58:23.382017Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.371759Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now to convert our results dictionary to a pandas dataframe\n",
    "\n",
    "ground_truth = pd.DataFrame(data=parsed_results)\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.384545Z",
     "iopub.status.busy": "2024-09-27T09:58:23.383486Z",
     "iopub.status.idle": "2024-09-27T09:58:23.388404Z",
     "shell.execute_reply": "2024-09-27T09:58:23.387824Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.384523Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# realised there were some issues with the question column - there are some outputs with nested listing\n",
    "# hence we need to flatten list further using the followinf function before exploding\n",
    "\n",
    "def flatten_list(obj):\n",
    "    if isinstance(obj[0], list):\n",
    "        return obj[0]\n",
    "    elif isinstance(obj[0], dict):\n",
    "        result = [i[0] for i in [list(item.values()) for item in obj]]\n",
    "        return result\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.389451Z",
     "iopub.status.busy": "2024-09-27T09:58:23.389153Z",
     "iopub.status.idle": "2024-09-27T09:58:23.394320Z",
     "shell.execute_reply": "2024-09-27T09:58:23.393774Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.389429Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth['Question'] = ground_truth['Question'].apply(lambda x : flatten_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.395409Z",
     "iopub.status.busy": "2024-09-27T09:58:23.395099Z",
     "iopub.status.idle": "2024-09-27T09:58:23.403209Z",
     "shell.execute_reply": "2024-09-27T09:58:23.402662Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.395388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets now explode the question column\n",
    "ground_truth = ground_truth.explode('Question', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.404217Z",
     "iopub.status.busy": "2024-09-27T09:58:23.403957Z",
     "iopub.status.idle": "2024-09-27T09:58:23.411454Z",
     "shell.execute_reply": "2024-09-27T09:58:23.410805Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.404197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.412444Z",
     "iopub.status.busy": "2024-09-27T09:58:23.412192Z",
     "iopub.status.idle": "2024-09-27T09:58:23.416578Z",
     "shell.execute_reply": "2024-09-27T09:58:23.415835Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.412424Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining a helper function to clean the question column in our ground truth dataset\n",
    "\n",
    "def ques_clean(ques_string):\n",
    "    pattern = r'(^Q:\\s|^[0-9]\\.\\s|^Q[0-9]:\\s|^Q[0-9]\\.\\s)'\n",
    "    \n",
    "    result = re.sub(pattern, \"\", ques_string)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.418090Z",
     "iopub.status.busy": "2024-09-27T09:58:23.417473Z",
     "iopub.status.idle": "2024-09-27T09:58:23.434125Z",
     "shell.execute_reply": "2024-09-27T09:58:23.433486Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.418056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth['Question'] = ground_truth['Question'].apply(lambda x : ques_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T09:58:23.438226Z",
     "iopub.status.busy": "2024-09-27T09:58:23.437946Z",
     "iopub.status.idle": "2024-09-27T09:58:23.458954Z",
     "shell.execute_reply": "2024-09-27T09:58:23.458361Z",
     "shell.execute_reply.started": "2024-09-27T09:58:23.438204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finally to throw the output into a .csv file\n",
    "\n",
    "ground_truth.to_csv(\"ground-truth-data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
